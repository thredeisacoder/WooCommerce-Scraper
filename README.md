# ğŸ›’ Enhanced WooCommerce Product Scraper

**CÃ´ng cá»¥ scraping sáº£n pháº©m WooCommerce máº¡nh máº½ vá»›i giao diá»‡n Ä‘á»“ há»a vÃ  tÃ­nh nÄƒng scraping chi tiáº¿t**

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![WooCommerce](https://img.shields.io/badge/WooCommerce-Compatible-purple.svg)](https://woocommerce.com/)

## ğŸ“‹ Má»¥c lá»¥c
- [TÃ­nh nÄƒng chÃ­nh](#-tÃ­nh-nÄƒng-chÃ­nh)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [CÃ¡ch sá»­ dá»¥ng](#-cÃ¡ch-sá»­-dá»¥ng)
- [Cáº¥u hÃ¬nh](#-cáº¥u-hÃ¬nh)
- [Dá»¯ liá»‡u thu tháº­p](#-dá»¯-liá»‡u-thu-tháº­p)
- [VÃ­ dá»¥](#-vÃ­-dá»¥)
- [API Reference](#-api-reference)
- [Troubleshooting](#-troubleshooting)

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

### ğŸ¨ **Giao diá»‡n Ä‘á»“ há»a (GUI)**
- Interface thÃ¢n thiá»‡n, dá»… sá»­ dá»¥ng
- Real-time progress tracking vÃ  logging
- TÃ¹y chá»n scraping trá»±c quan
- URL templates cÃ³ sáºµn
- Export Ä‘a Ä‘á»‹nh dáº¡ng (JSON/CSV)

### ğŸ” **Scraping thÃ´ng minh**
- **Scraping cÆ¡ báº£n**: Nhanh, láº¥y thÃ´ng tin tá»« product listing
- **Scraping chi tiáº¿t**: Truy cáº­p tá»«ng trang sáº£n pháº©m Ä‘á»ƒ láº¥y Ä‘áº§y Ä‘á»§ thÃ´ng tin
- Há»— trá»£ 30+ CSS selectors cho cÃ¡c theme khÃ¡c nhau
- Auto-pagination vá»›i multiple page formats
- Retry mechanism vá»›i exponential backoff

### ğŸ›¡ï¸ **Báº£o máº­t vÃ  á»•n Ä‘á»‹nh**
- Proxy rotation tÃ­ch há»£p
- Rate limiting vÃ  delay configurable
- Error handling toÃ n diá»‡n
- User-agent rotation
- Respectful scraping practices

### ğŸ“Š **Xuáº¥t dá»¯ liá»‡u vÃ  bÃ¡o cÃ¡o**
- JSON vÃ  CSV export
- Real-time statistics
- Detailed logging
- Progress tracking
- Data validation

## ğŸ”§ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.7 hoáº·c cao hÆ¡n
- Káº¿t ná»‘i Internet á»•n Ä‘á»‹nh
- 50MB dung lÆ°á»£ng trá»‘ng

### CÃ i Ä‘áº·t dependencies

```bash
# Clone hoáº·c download project
git clone https://github.com/thredeisacoder/WooCommerce-Scraper
cd WooCommerce-Scraper

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

### Dependencies chÃ­nh
```
requests==2.31.0
beautifulsoup4==4.12.2
lxml==4.9.3
```

## ğŸ–¥ï¸ CÃ¡ch sá»­ dá»¥ng

### ğŸ¯ **PhÆ°Æ¡ng phÃ¡p 1: GUI (Khuyáº¿n nghá»‹ cho ngÆ°á»i má»›i)**

```bash
python gui.py
```

**TÃ­nh nÄƒng GUI:**
- ğŸŒ **URL Input**: Nháº­p trá»±c tiáº¿p vá»›i validation
- âš™ï¸ **Settings**: CÃ i Ä‘áº·t pages, delay, proxy trá»±c quan
- ğŸ“‹ **Detailed Mode**: Toggle scraping chi tiáº¿t
- ğŸ’¾ **Export Options**: Chá»n format vÃ  output directory
- ğŸ“Š **Real-time Log**: Theo dÃµi progress vá»›i emoji vÃ  colors
- ğŸ¯ **Quick URLs**: Templates sáºµn cÃ³ Ä‘á»ƒ test

**Quy trÃ¬nh sá»­ dá»¥ng GUI:**
1. Má»Ÿ GUI: `python gui.py`
2. Nháº­p URL WooCommerce
3. Chá»n settings (pages, delay, detailed mode)
4. Chá»n export format vÃ  folder
5. Click "ğŸš€ Báº¯t Ä‘áº§u Scraping"
6. Theo dÃµi real-time log vÃ  Ä‘á»£i káº¿t quáº£

### ğŸ’» **PhÆ°Æ¡ng phÃ¡p 2: Command Line**

```bash
# Scraping cÆ¡ báº£n
python scraper.py https://shop.example.com

# Scraping chi tiáº¿t (cháº­m hÆ¡n nhÆ°ng Ä‘áº§y Ä‘á»§)
python scraper.py https://shop.example.com --detailed

# Full options
python scraper.py https://shop.example.com \
  --max-pages 10 \
  --delay 2.0 \
  --detailed \
  --export-json products.json \
  --export-csv products.csv

# Chá»‰ xem statistics
python scraper.py https://shop.example.com --stats-only

# KhÃ´ng dÃ¹ng proxy
python scraper.py https://shop.example.com --no-proxy
```

**Command Line Options:**
- `url`: URL WooCommerce shop (required)
- `--max-pages INT`: Sá»‘ trang tá»‘i Ä‘a (default: 5)
- `--delay FLOAT`: Delay giá»¯a requests (default: 1.0s)
- `--detailed`: Enable detailed scraping
- `--no-proxy`: Disable proxy
- `--export-json FILE`: Export to JSON
- `--export-csv FILE`: Export to CSV  
- `--quiet`: Suppress console output
- `--stats-only`: Chá»‰ hiá»ƒn thá»‹ thá»‘ng kÃª

### ğŸ **PhÆ°Æ¡ng phÃ¡p 3: Python API**

#### Basic Usage
```python
from scraper import WooCommerceScraper

# Khá»Ÿi táº¡o scraper
scraper = WooCommerceScraper("https://shop.example.com")

# Scrape má»™t trang
products = scraper.scrape_page("https://shop.example.com/shop")

# Scrape nhiá»u trang vá»›i chi tiáº¿t
products = scraper.scrape_all_pages(
    "https://shop.example.com/shop", 
    max_pages=5, 
    fetch_detailed=True
)

# Export results
scraper.export_to_json("products.json")
scraper.export_to_csv("products.csv")

# Get statistics
stats = scraper.get_statistics()
print(f"Total products: {stats['total_products']}")
```

#### Advanced Usage
```python
# Custom configuration
scraper = WooCommerceScraper(
    base_url="https://shop.example.com",
    use_proxy=True,
    delay=2.0
)

# Process results
for product in products:
    print(f"Product: {product.title}")
    print(f"Price: {product.price}")
    if product.description:
        print(f"Description: {product.description[:100]}...")
    if product.sku:
        print(f"SKU: {product.sku}")
    print("-" * 50)
```

#### Simple Function (Backward Compatible)
```python
from scraper import simple_scrape

# Quick scraping
products = simple_scrape("https://shop.example.com", detailed=True)
```

## âš™ï¸ Cáº¥u hÃ¬nh

### config.json
Táº¡o file `config.json` Ä‘á»ƒ custom settings:

```json
{
  "default_settings": {
    "delay": 1.0,
    "max_pages": 5,
    "timeout": 30,
    "max_retries": 3,
    "use_proxy": true
  },
  "headers": {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Accept-Encoding": "gzip, deflate",
    "Connection": "keep-alive"
  },
  "selectors": {
    "product_containers": [
      "li.product",
      ".wc-block-grid__product",
      ".product-item",
      ".type-product"
    ],
    "title": [
      "h2.woocommerce-loop-product__title",
      ".wc-block-grid__product-title",
      ".product-title"
    ],
    "price": [
      "span.woocommerce-Price-amount",
      ".wc-block-grid__product-price",
      ".price"
    ],
    "description": [
      ".woocommerce-product-details__short-description",
      ".product-short-description",
      ".entry-summary p"
    ],
    "sku": [
      ".sku",
      ".product-meta .sku",
      "[itemprop='sku']"
    ],
    "stock": [
      ".stock",
      ".availability",
      ".woocommerce-stock-status"
    ],
    "category": [
      ".woocommerce-breadcrumb a",
      ".product_meta .posted_in a"
    ]
  },
  "export_options": {
    "default_json_file": "products.json",
    "default_csv_file": "products.csv"
  }
}
```

### Proxy Configuration
Proxy Ä‘Æ°á»£c cáº¥u hÃ¬nh sáºµn vá»›i IP2World. Äá»ƒ thay Ä‘á»•i:

```python
scraper = WooCommerceScraper(
    base_url="https://shop.example.com",
    use_proxy=False  # Táº¯t proxy
)
```

## ğŸ“¦ Dá»¯ liá»‡u thu tháº­p

### Product Schema
```python
@dataclass
class Product:
    title: str           # TÃªn sáº£n pháº©m
    price: str           # GiÃ¡ (vá»›i currency)
    link: str            # URL Ä‘áº¿n trang sáº£n pháº©m
    image_url: str       # URL hÃ¬nh áº£nh chÃ­nh
    description: str     # MÃ´ táº£ ngáº¯n (optional)
    sku: str            # MÃ£ sáº£n pháº©m (optional)
    stock_status: str   # TÃ¬nh tráº¡ng kho (optional)
    category: str       # Danh má»¥c (optional)
```

### Data Coverage
- **CÆ¡ báº£n**: title, price, link, image (100% coverage)
- **Chi tiáº¿t**: description, SKU, stock, category (60-90% coverage)

### Export Formats

#### JSON Output
```json
[
  {
    "title": "Premium T-Shirt",
    "price": "$29.99",
    "link": "https://shop.example.com/product/premium-tshirt/",
    "image_url": "https://shop.example.com/wp-content/uploads/tshirt.jpg",
    "description": "Comfortable premium cotton t-shirt with modern fit...",
    "sku": "TSH-001",
    "stock_status": "In Stock",
    "category": "Clothing"
  }
]
```

#### CSV Output
```csv
title,price,link,image_url,description,sku,stock_status,category
Premium T-Shirt,$29.99,https://shop.example.com/product/premium-tshirt/,https://shop.example.com/wp-content/uploads/tshirt.jpg,Comfortable premium cotton...,TSH-001,In Stock,Clothing
```

## ğŸ“Š VÃ­ dá»¥

### Console Output
```
[10:30:15] ğŸš€ Báº®T Äáº¦U SCRAPING Má»šI
[10:30:15] ğŸŒ URL: https://roostick.com/shop
[10:30:15] ğŸ“„ Sá»‘ trang tá»‘i Ä‘a: 5
[10:30:15] â±ï¸ Delay: 1.0s
[10:30:15] ğŸ”’ Proxy: CÃ³
[10:30:15] ğŸ“‹ Scrape chi tiáº¿t: CÃ³
[10:30:16] ğŸ”§ Khá»Ÿi táº¡o scraper cho URL: https://roostick.com/shop
[10:30:17] ğŸ” Báº¯t Ä‘áº§u scraping CHI TIáº¾T tá»‘i Ä‘a 5 trang (sáº½ cháº­m hÆ¡n)...
[10:30:18] Found 12 products using selector: li.product
[10:30:18] Processing product 1/12 with detailed info...
[10:30:19] Product 'Premium Coffee Beans...' - Found: description, SKU, stock
[10:30:20] âœ… TÃ¬m tháº¥y 12 sáº£n pháº©m
[10:30:20] ğŸ’¾ ÄÃ£ xuáº¥t JSON: products_20241215_103020.json
[10:30:20] ğŸ“Š === THá»NG KÃŠ ===
[10:30:20]    Total Products: 12
[10:30:20]    Products With Price: 12
[10:30:20]    Products With Image: 12
[10:30:20]    Price Coverage: 100.0%
[10:30:20]    Image Coverage: 100.0%
```

### Statistics Example
```python
stats = scraper.get_statistics()
print(stats)
# Output:
{
    "total_products": 48,
    "products_with_price": 48,
    "products_with_image": 46,
    "price_coverage": "100.0%",
    "image_coverage": "95.8%"
}
```

## ğŸ“š API Reference

### WooCommerceScraper Class

#### Constructor
```python
WooCommerceScraper(base_url, use_proxy=True, delay=1.0)
```

#### Methods
```python
# Scrape single page
scrape_page(url, fetch_detailed=False) -> List[Product]

# Scrape multiple pages  
scrape_all_pages(start_url, max_pages=10, fetch_detailed=False) -> List[Product]

# Export methods
export_to_json(filename=None)
export_to_csv(filename=None)

# Utility methods
get_statistics() -> Dict[str, Any]
print_products()
```

### Functions
```python
# Simple scraping function
simple_scrape(url, detailed=False) -> List[Product]
```

## ğŸ› ï¸ Troubleshooting

### âŒ **Lá»—i thÆ°á»ng gáº·p**

#### "No products found"
```
NguyÃªn nhÃ¢n: Website sá»­ dá»¥ng cáº¥u trÃºc HTML khÃ¡c
Giáº£i phÃ¡p:
1. Kiá»ƒm tra URL cÃ³ Ä‘Ãºng lÃ  trang shop khÃ´ng
2. Thá»­ vá»›i --detailed Ä‘á»ƒ scrape tá»« product pages
3. TÄƒng delay: --delay 2.0
4. Check config.json selectors
```

#### "Connection timeout"
```
NguyÃªn nhÃ¢n: Máº¡ng cháº­m hoáº·c website cháº·n
Giáº£i phÃ¡p:
1. Thá»­ --no-proxy
2. TÄƒng delay: --delay 3.0
3. Kiá»ƒm tra internet connection
4. Thá»­ URL khÃ¡c Ä‘á»ƒ test
```

#### "Import error"
```
NguyÃªn nhÃ¢n: Thiáº¿u dependencies
Giáº£i phÃ¡p:
pip install -r requirements.txt
```

### ğŸ”§ **Performance Tips**

1. **Báº¯t Ä‘áº§u nhá»**: Test vá»›i 1-2 trang trÆ°á»›c
2. **Tá»‘i Æ°u delay**: 1-2s cho sites nhanh, 3-5s cho sites cháº­m
3. **Detailed mode**: Chá»‰ dÃ¹ng khi cáº§n thiáº¿t (cháº­m hÆ¡n 3-5x)
4. **Proxy**: Giá»¯ nguyÃªn enabled Ä‘á»ƒ trÃ¡nh bá»‹ block

### ğŸ“‹ **Debug Mode**

```bash
# Enable verbose logging
python scraper.py https://shop.example.com --detailed --max-pages 1

# Check logs
tail -f scraper.log
```

## ğŸ“„ File Structure

```
woocommerce-scraper/
â”œâ”€â”€ scraper.py          # Core scraper engine
â”œâ”€â”€ gui.py             # GUI interface  
â”œâ”€â”€ config.json        # Configuration file
â”œâ”€â”€ requirements.txt   # Dependencies
â”œâ”€â”€ README.md         # This file
â”œâ”€â”€ GUI_GUIDE.md      # GUI usage guide
â”œâ”€â”€ scraper.log       # Runtime logs
â””â”€â”€ products_*.json   # Output files
```

## âš¡ Performance

- **Basic scraping**: ~1-2 seconds per page
- **Detailed scraping**: ~5-10 seconds per page  
- **Memory usage**: ~50-100MB for 1000 products
- **Success rate**: 95%+ for standard WooCommerce themes

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## âš–ï¸ Disclaimer

**Sá»­ dá»¥ng cÃ³ trÃ¡ch nhiá»‡m:**
- TuÃ¢n thá»§ robots.txt cá»§a website
- KhÃ´ng spam quÃ¡ nhiá»u requests
- Respect website's terms of service
- Chá»‰ scrape dá»¯ liá»‡u cÃ´ng khai
- Sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»£p phÃ¡p

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á»:
1. Kiá»ƒm tra [Troubleshooting](#-troubleshooting)
2. Xem [GUI Guide](GUI_GUIDE.md)
3. Check logs trong `scraper.log`
4. Táº¡o issue vá»›i log details

---

**Made with â¤ï¸ for the WooCommerce community** 
